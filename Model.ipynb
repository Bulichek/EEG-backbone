{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, normalize\n",
    "\n",
    "from src.utils import arr_to_dict, fourier_transform, metric_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим к данным следующие методы процессинга:\n",
    "\n",
    "- Преобразование Фурье и последующее использование амплитудного спектра.\n",
    "- Нормализация полученных спектров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = np.load(\"data/filtered_data.npy\", allow_pickle=True)\n",
    "data = arr_to_dict(data_arr)\n",
    "\n",
    "test_data_arr = np.load(\"data/two_stage_test.npy\", allow_pickle=True)\n",
    "test_data = arr_to_dict(test_data_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение 2-х преобразованных сигналов в один массив\n",
    "X = np.hstack(\n",
    "    (\n",
    "        fourier_transform(data['signal_1']),\n",
    "        fourier_transform(data['signal_2']),\n",
    "    )\n",
    ")\n",
    "X_test = np.hstack(\n",
    "    (\n",
    "        fourier_transform(test_data['signal_1']),\n",
    "        fourier_transform(test_data['signal_2']),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Бинаризация таргетов\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data['label'])\n",
    "y_test = le.transform(test_data['label'])\n",
    "\n",
    "# Сплит данных на train/val\n",
    "split = np.load(\"data/splitted_idx.npy\", allow_pickle=True)\n",
    "X_train, X_val = X[split['train']],  X[split['val']]\n",
    "y_train, y_val = y[split['train']],  y[split['val']]\n",
    "\n",
    "# Нормализация данных\n",
    "X_train = normalize(X_train)\n",
    "X_val = normalize(X_val)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "del data_arr\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Были использованы более простые модели классического МЛ. Наилучший результат показал бустинг со следующими параметрами:\n",
    "- `max_depth = 4`. Был взят меньше для борьбы с переобучением\n",
    "- `scale_pos_weight = 1`. Борьба с дисбалансом классов.\n",
    "- `sampling_method = gradient_based`.\n",
    "- `objective = binary:logitraw`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***XGboost***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:41:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:1205: Starting in XGBoost 1.4.0, the default evaluation metric used with the objective 'binary:logitraw' was changed from 'auc' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective='binary:logitraw',\n",
       "              predictor='auto', random_state=42, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\n",
    "    tree_method='gpu_hist',\n",
    "    max_depth=4,\n",
    "    scale_pos_weight=0.01,\n",
    "    sampling_method='gradient_based',\n",
    "    objective='binary:logitraw',\n",
    "    random_state=42,\n",
    ")\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Sleep stage 4       0.93      1.00      0.96      2388\n",
      "Sleep stage W       1.00      1.00      1.00    162109\n",
      "\n",
      "     accuracy                           1.00    164497\n",
      "    macro avg       0.96      1.00      0.98    164497\n",
      " weighted avg       1.00      1.00      1.00    164497\n",
      " \n",
      "\n",
      "Val\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Sleep stage 4       0.88      0.98      0.93      1056\n",
      "Sleep stage W       1.00      1.00      1.00     69443\n",
      "\n",
      "     accuracy                           1.00     70499\n",
      "    macro avg       0.94      0.99      0.96     70499\n",
      " weighted avg       1.00      1.00      1.00     70499\n",
      " \n",
      "\n",
      "Test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Sleep stage 4       1.00      0.96      0.98      8208\n",
      "Sleep stage W       0.96      1.00      0.98      7488\n",
      "\n",
      "     accuracy                           0.98     15696\n",
      "    macro avg       0.98      0.98      0.98     15696\n",
      " weighted avg       0.98      0.98      0.98     15696\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_report(\n",
    "    xgb_clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    le.classes_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***LogisticRegression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=500, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_clf = LogisticRegression(class_weight='balanced', max_iter=500, random_state=42)\n",
    "logreg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Sleep stage 4       0.53      0.99      0.69      2388\n",
      "Sleep stage W       1.00      0.99      0.99    162109\n",
      "\n",
      "     accuracy                           0.99    164497\n",
      "    macro avg       0.77      0.99      0.84    164497\n",
      " weighted avg       0.99      0.99      0.99    164497\n",
      " \n",
      "\n",
      "Val\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Sleep stage 4       0.53      0.99      0.69      1056\n",
      "Sleep stage W       1.00      0.99      0.99     69443\n",
      "\n",
      "     accuracy                           0.99     70499\n",
      "    macro avg       0.76      0.99      0.84     70499\n",
      " weighted avg       0.99      0.99      0.99     70499\n",
      " \n",
      "\n",
      "Test\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Sleep stage 4       1.00      0.95      0.97      8208\n",
      "Sleep stage W       0.95      1.00      0.97      7488\n",
      "\n",
      "     accuracy                           0.97     15696\n",
      "    macro avg       0.97      0.97      0.97     15696\n",
      " weighted avg       0.97      0.97      0.97     15696\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_report(\n",
    "    logreg_clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    le.classes_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте рассмотрим, какие эксперименты были проведены и каков их результат:\n",
    "\n",
    "1. Использованные модели. Было решено провести эксперименты с двумя моделями:\n",
    "\n",
    "    - LogisticRegression, как самый простой подход к решению задачи.\n",
    "    - XGboost. Был выбран в качестве более сильной модели, так как, как правило, дает неплохие результаты в сравнении с остальными подходами классического МЛ.\n",
    "\n",
    "2. Предобработка данных: \n",
    "    - Применение моделей к сырому, никак не обработанному сигналу.\n",
    "    - Скейлинг, нормализация сырого сигнала.\n",
    "    - Преобразование Фурье.\n",
    "    - Преобразование Фурье + нормализация.\n",
    "\n",
    "Обе модели обучались с учетом дисбаланса классов, использовались соответсвующие аргументы моделей: `scale_pos_weight` для `XGBClassifier` и `class_weight` для `LogisticRegression`.\n",
    "\n",
    "Без использования какой-либо обработки сигнала обе модели показали очень плохой результат на тестовых данных. Бустинг смог достичь высоких результатов на train и val выборках, логистичсекая регрессия показала себя хорошо только на трейне.\n",
    "\n",
    "Скейлинг и нормализация незначительно улучишили результаты на тесте только для бустинга, но качество было далеко от бейзлайна. Использование только преобразования Фурье ни привело к улучшению результатов. Все это можно обяснить тем, что train и test выборки из разных распределений, что было выявлено на этапе `EDA`.\n",
    "\n",
    "Резко к улучшению качества модели на тесте приводит нормализация результатов преобразования Фурье. Получаем следующие результаты на тестовой выборке:\n",
    "\n",
    "1. XGboost:\n",
    "    - Sleep stage 4: Precision - 1.00, Recall - 0.96\n",
    "    - Sleep stage W: Precision - 0.96, Recall - 1.00\n",
    "    \n",
    "2. LogisticRegression:\n",
    "    - Sleep stage 4: Precision - 1.00, Recall - 0.95\n",
    "    - Sleep stage W: Precision - 0.95, Recall - 1.00\n",
    "\n",
    "Можно заметить, что качество моделей практически одинаково, однако логистическая регрессия, в отличие от бустинга, имеет плохие метрики на обучающей выборке. \n",
    "\n",
    "Таким образом, для данного сетапа задачу можно хорошо решить, используя методы классического МЛ, но правильно предобработав данные.\n",
    "\n",
    "В рамках backnone задачи в дальнейшем можно рассмотреть нейросетевой подход. Использовать другие методы обработки сигнала, например, MFCC. В качестве модели можно использовать [CNN](https://arxiv.org/pdf/1904.10255.pdf), обученную на большом корпусе EEG данных, которая потом будет использоваться в качестве feature extractor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20da027535b4caab94115be186f2833452b21112f9383cd2ef91a310ddf027e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
